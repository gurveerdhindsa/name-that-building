{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FbUjaLe-p9n5"
   },
   "source": [
    "# name-that-building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "c0Y3Qa5-qDmx",
    "outputId": "9c781478-cea4-4ca4-d72d-d23ce0f6bcbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os, sys\n",
    "import pandas as pd\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 510
    },
    "colab_type": "code",
    "id": "JM2dqfAUqHA5",
    "outputId": "7b621118-c82b-42db-db84-94535ec6e785"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Image Label\n",
      "0    drive/My Drive/All_Images_500x500/AA/285_2.jpg    AA\n",
      "1    drive/My Drive/All_Images_500x500/AA/548_2.jpg    AA\n",
      "2    drive/My Drive/All_Images_500x500/AA/958-1.jpg    AA\n",
      "3    drive/My Drive/All_Images_500x500/AA/607_2.jpg    AA\n",
      "4    drive/My Drive/All_Images_500x500/AA/182_1.jpg    AA\n",
      "..                                              ...   ...\n",
      "235  drive/My Drive/All_Images_500x500/TB/954-1.jpg    TB\n",
      "236  drive/My Drive/All_Images_500x500/TB/905_3.jpg    TB\n",
      "237  drive/My Drive/All_Images_500x500/TB/548_5.jpg    TB\n",
      "238  drive/My Drive/All_Images_500x500/TB/533_1.jpg    TB\n",
      "239  drive/My Drive/All_Images_500x500/TB/157_1.jpg    TB\n",
      "\n",
      "[240 rows x 2 columns]\n",
      "                                               Image Label\n",
      "0     drive/My Drive/All_Images_500x500/AA/120-4.jpg    AA\n",
      "1     drive/My Drive/All_Images_500x500/AA/548_5.jpg    AA\n",
      "2     drive/My Drive/All_Images_500x500/AA/713_7.jpg    AA\n",
      "3     drive/My Drive/All_Images_500x500/AA/219_1.jpg    AA\n",
      "4     drive/My Drive/All_Images_500x500/AA/548_4.jpg    AA\n",
      "...                                              ...   ...\n",
      "2789  drive/My Drive/All_Images_500x500/TB/954-2.jpg    TB\n",
      "2790  drive/My Drive/All_Images_500x500/TB/153_3.jpg    TB\n",
      "2791  drive/My Drive/All_Images_500x500/TB/250_1.jpg    TB\n",
      "2792  drive/My Drive/All_Images_500x500/TB/606_3.jpg    TB\n",
      "2793  drive/My Drive/All_Images_500x500/TB/373-2.jpg    TB\n",
      "\n",
      "[2794 rows x 2 columns]\n",
      "240\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "buildingCodes = [\"AA\", \"CB\", \"CT\", \"DT\", \"FH\",\"HP\",\"HS\", \"LB\", \"MC\",\n",
    "             \"ME\", \"ML\", \"PA\", \"RB\", \"RO\", \"SA\", \"TB\"]\n",
    "test = []\n",
    "training = []\n",
    "width = 500\n",
    "height = 500\n",
    "combinedDataFrame = []\n",
    "validationData=[]\n",
    "validationDataFrame = []\n",
    "testDataFrame = []\n",
    "# validation , test and training dataframes\n",
    "for building in buildingCodes:\n",
    "  try:\n",
    "    path =  glob(\"drive/My Drive/All_Images_500x500/\" + str(building) + \"/*.jpg\")\n",
    "    \n",
    "    for i in range(15): # randomly select 15 images from each building directory\n",
    "      validation = []\n",
    "      test =[]\n",
    "      randIndex = random.randint(0,len(path)-1)\n",
    "      test.append(path.pop(randIndex)) # removing the image path once appened to the dataset\n",
    "      test.append(building)\n",
    "      testDataFrame.append(test)\n",
    "\n",
    "      validation.append(path.pop(-randIndex)) # removing the image path once appened to the dataset\n",
    "      validation.append(building)\n",
    "      validationDataFrame.append(validation)\n",
    "\n",
    "    for img in path: \n",
    "      data = []\n",
    "      data.append(img)\n",
    "      data.append(building)\n",
    "      combinedDataFrame.append(data) # appending the training dataset\n",
    "\n",
    "   \n",
    "  except (IOError, SyntaxError) as e:\n",
    "    print('Bad file:', img) \n",
    "    path.remove(img)\n",
    "# creating a panda dataframe for test, train and validation\n",
    "vdf = pd.DataFrame(validationDataFrame ,columns=[\"Image\",\"Label\"])\n",
    "df = pd.DataFrame(combinedDataFrame,columns=[\"Image\",\"Label\"])\n",
    "tdf = pd.DataFrame(testDataFrame,columns=[\"Image\",\"Label\"])\n",
    "print(vdf)\n",
    "print(df)\n",
    "print(len(tdf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "mQCHhirvqLaS",
    "outputId": "56a26111-2eaf-4578-99af-f27b8db6183c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2794 validated image filenames belonging to 16 classes.\n",
      "Found 240 validated image filenames belonging to 16 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "\n",
    "WIDTH = 500\n",
    "HEIGHT = 500\n",
    "BATCH_SIZE = 50\n",
    "# pre training the model\n",
    "# preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    fill_mode='nearest',\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2) \n",
    "                                   \n",
    "validation_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    fill_mode='nearest',\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2) \n",
    "# training set\n",
    "train_generator = train_datagen.flow_from_dataframe(df,x_col= \"Image\", y_col = \"Label\", classes = buildingCodes, target_size=(500,500), batch_size = 50) \n",
    "# validation set\n",
    "validation_generator = validation_datagen.flow_from_dataframe(vdf,x_col= \"Image\", y_col = \"Label\", classes = buildingCodes, target_size=(500,500), BATCH_SIZE = 24)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 697
    },
    "colab_type": "code",
    "id": "K7mIFAWMqNDQ",
    "outputId": "d7640a66-f0b2-4df8-acab-406ccdd67a58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 500, 500, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 498, 498, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 498, 498, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 248, 248, 32)      9248      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 248, 248, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 82, 82, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 40, 40, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 40, 40, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 38, 38, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 38, 38, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 250)               1152250   \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                4016      \n",
      "=================================================================\n",
      "Total params: 1,184,906\n",
      "Trainable params: 1,184,906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.core import Activation\n",
    "from keras import optimizers\n",
    "import keras\n",
    "# saving the weights \n",
    "mycall_back = keras.callbacks.ModelCheckpoint('MyModel-{epoch:02d}-{val_loss:.2f}.hdf5', monitor='val_loss', verbose=0, \n",
    "                                          save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "# model layers\n",
    "image_input = Input((500,500,3))\n",
    "image_model = Conv2D(64,(10,10), strides=(4,4))(image_input)\n",
    "image_model = Activation('relu')(image_model)\n",
    "image_model = Conv2D(128,(4,4))(image_input)\n",
    "image_model = Activation('relu')(image_model)\n",
    "\n",
    "image_model = MaxPooling2D(pool_size=(3,3))(image_model)\n",
    "image_model = Conv2D(32,(3,3))(image_input)\n",
    "image_model = Activation('relu')(image_model)\n",
    "\n",
    "image_model = Conv2D(32,(3,3), strides=(2,2))(image_model)\n",
    "image_model = Activation('relu')(image_model)\n",
    "image_model = MaxPooling2D(pool_size=(3,3))(image_model)\n",
    "image_model = Conv2D(32,(3,3), strides=(2,2))(image_model)\n",
    "image_model = Activation('relu')(image_model)\n",
    "image_model = Conv2D(32,(3,3), strides=(1,1))(image_model)\n",
    "image_model = Activation('relu')(image_model)\n",
    "image_model = MaxPooling2D(pool_size=(3,3))(image_model)\n",
    "image_model = Dropout(0.5)(image_model)\n",
    "image_model = Flatten()(image_model)\n",
    "image_model = Dense(250)(image_model)\n",
    "image_model = Activation('relu')(image_model)\n",
    "#16 classes softmax function as last layer\n",
    "output = Dense(16, activation='softmax')(image_model)\n",
    "\n",
    "model = Model(inputs=image_input, outputs=output)\n",
    "# adam optimizer with categorical_crossentropy\n",
    "model.compile(loss='categorical_crossentropy',optimizer = 'adam',metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QOA-Nf5QqNlI"
   },
   "outputs": [],
   "source": [
    "\n",
    "MODEL_FILE = 'model.h5'\n",
    "# running model with 50 epoch and 50 steps per epoch with batch sizes of 50\n",
    "history = model.fit_generator(train_generator,steps_per_epoch=50,\n",
    "epochs=50,\n",
    "validation_data=validation_generator,\n",
    "validation_steps=10, callbacks = [mycall_back])\n",
    "model.save(MODEL_FILE)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zRH6AlhQqbbZ"
   },
   "outputs": [],
   "source": [
    "!wget https://github.com/rohank07/ML_A3/blob/master/model.zip?raw=true\n",
    "!unzip model.zip?raw=true\n",
    "# loading model from github repository\n",
    "from keras.models import load_model\n",
    "from google.colab import files\n",
    "model = load_model('model/model.h5') # loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "lQjifW5Nqg6x",
    "outputId": "ac762440-6a11-4b3d-f1dd-2d3053400f87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 240 validated image filenames belonging to 16 classes.\n",
      "Found 240 validated image filenames belonging to 16 classes.\n",
      "Found 240 validated image filenames belonging to 16 classes.\n",
      "Found 240 validated image filenames belonging to 16 classes.\n",
      "Found 240 validated image filenames belonging to 16 classes.\n",
      "Found 240 validated image filenames belonging to 16 classes.\n",
      "Found 240 validated image filenames belonging to 16 classes.\n",
      "Found 240 validated image filenames belonging to 16 classes.\n",
      "Found 240 validated image filenames belonging to 16 classes.\n",
      "Found 240 validated image filenames belonging to 16 classes.\n",
      "Found 240 validated image filenames belonging to 16 classes.\n",
      "Found 240 validated image filenames belonging to 16 classes.\n",
      "Found 240 validated image filenames belonging to 16 classes.\n",
      "Found 240 validated image filenames belonging to 16 classes.\n",
      "Found 240 validated image filenames belonging to 16 classes.\n",
      "Found 240 validated image filenames belonging to 16 classes.\n"
     ]
    }
   ],
   "source": [
    "#testing on training set\n",
    "dic = {}\n",
    "for building in buildingCodes:\n",
    "  y_pred = []\n",
    "  y_true = []\n",
    "  #preprocessing the test set\n",
    "  dataframe = pd.DataFrame(test)\n",
    "  predict_gen = ImageDataGenerator(\n",
    "      rescale = 1./255, fill_mode='nearest',\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2)\n",
    "  \n",
    "  pred_gen = predict_gen.flow_from_dataframe(\n",
    "      tdf, #test data frame\n",
    "      x_col= \"Image\", \n",
    "      y_col = \"Label\", \n",
    "      classes = buildingCodes, \n",
    "      target_size=(500,500),\n",
    "      batch_size = 50) \n",
    "  probs = model.predict(pred_gen)\n",
    "  for i in range(15):\n",
    "    j = np.argmax(probs[i]) \n",
    "    y_true.append(building) # appending the label\n",
    "    y_pred.append(buildingCodes[j])\n",
    "\n",
    "  dic[building] = [y_true,y_pred]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "autNAkWgvRma",
    "outputId": "cef0c5f0-d4b5-48f0-d788-59359c065177"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.26666667 0.         0.6        0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.06666667 0.         0.06666667 0.        ]\n",
      "[0.         0.06779661 0.         0.07258065 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.03030303 0.         0.0625     0.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "# precision and recall scores\n",
    "y_true = []\n",
    "y_pred = []\n",
    "scores = {}\n",
    "for i in dic:\n",
    "  y_true += dic[i][0]\n",
    "  y_pred += dic[i][1]\n",
    "# Lowest recall RB and SA\n",
    "print(metrics.recall_score(y_true,y_pred, labels=buildingCodes, average =None ,sample_weight=None))\n",
    "# best precision DT\n",
    "print(metrics.precision_score(y_true,y_pred, labels=buildingCodes, average =None ,sample_weight=None))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "trainModel.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
